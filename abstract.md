In recent years, there has been a focus on understanding the performance of neural networks---often classifiers---on out-of-distribution (OOD) data splits. For example, if a classifier is trained on images from 2012, what will its performance be on images collected from 2022? Such understanding is particularly important in climate related applications, where measuring robustness to distribution shift (geographical, temporal, etc.) can give us an idea of how confidently to trust classifiers in OOD settings. Recently, models trained on internet scale data in a self-supervised manner have shown unprecedented robustness in image classification tasks. However, it remains unclear if features extracted by these models are useful in climate related image classification applications. In this paper, we take a deeper look at the climate related datasets in the Wilds benchmark (iWildsCam, FMoW, PovertyMap, and GlobalWheat). We probe whether existing pre-trained models provide good features for the above datasets. We also investigate various in-distribution (ID) fine-tuning strategies, comparing the marginal value of each strategy in OOD evaluation.
